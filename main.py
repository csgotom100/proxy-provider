import json, urllib.request, yaml, os, ssl, warnings, re, base64, time
from datetime import datetime, timedelta, timezone

warnings.filterwarnings("ignore")

OUT_DIR = './sub'
MANUAL_FILE = './urls/manual_json.txt'
os.makedirs(OUT_DIR, exist_ok=True)
ctx = ssl._create_unverified_context()

def get_geo(ip):
    try:
        clean_ip = ip.replace('[','').replace(']','')
        if not re.match(r'^\d', clean_ip) and not ':' in clean_ip: return "ğŸ³ï¸"
        url = f"http://ip-api.com/json/{clean_ip}?fields=countryCode"
        with urllib.request.urlopen(url, timeout=3) as r:
            code = json.loads(r.read().decode()).get('countryCode', 'UN')
            return "".join(chr(ord(c) + 127397) for c in code.upper())
    except: return "ğŸ³ï¸"

def parse_strict(d):
    """ä¸¥æ ¼ä¾æ® JSON ç»“æ„æå–èŠ‚ç‚¹"""
    try:
        if not isinstance(d, dict): return None
        
        # æå–æ ¸å¿ƒä¸‰è¦ç´ 
        s_raw = d.get('server') or d.get('add') or d.get('address')
        p = d.get('port') or d.get('server_port') or d.get('listen_port')
        u = d.get('uuid') or d.get('password') or d.get('id') or d.get('auth') or d.get('user_id')
        
        # å¤„ç† Alvin æºä¸­å¸¸è§çš„ "server": "ip:port" è¿å†™æƒ…å†µ
        if s_raw and ':' in str(s_raw) and not p:
            parts = str(s_raw).split(':')
            s = "".join(parts[:-1]).replace('[','').replace(']','')
            p = parts[-1]
        else:
            s = str(s_raw).replace('[','').replace(']','') if s_raw else None
            
        if not (s and p and u):
            # ç‰¹æ®Šå¤„ç† NaiveProxy å­—ç¬¦ä¸²æ ¼å¼
            if 'proxy' in d and 'https://' in str(d.get('proxy')):
                m = re.search(r'https://(.*):(.*)@([^:]+):(\d+)', d.get('proxy'))
                if m: return {"s": m.group(3), "p": int(m.group(4)), "t": "naive", "u": m.group(1), "pass": m.group(2), "sn": m.group(3)}
            return None

        # åˆ¤å®šåè®®é€»è¾‘ (ä¸¥æ ¼æ ¹æ® type æˆ–ç‰¹æœ‰å­—æ®µ)
        t_raw = str(d.get('type', '')).lower()
        if 'juicity' in t_raw or 'juicity' in d: t = 'juicity'
        elif 'hy' in t_raw or 'hysteria2' in t_raw or 'auth' in d: t = 'hysteria2'
        else: t = 'vless' # é»˜è®¤ä¸º VLESS

        node = {"s": s, "p": int(p), "u": str(u), "t": t}
        
        # æå– SNI å’Œ Reality å­—æ®µ
        tls = d.get('tls', {}) if isinstance(d.get('tls'), dict) else {}
        node["sn"] = d.get('sni') or d.get('servername') or tls.get('server_name') or ""
        
        ry = d.get('reality-opts') or d.get('reality') or tls.get('reality') or {}
        if isinstance(ry, dict) and (ry.get('public-key') or ry.get('publicKey')):
            node["pbk"] = ry.get('public-key') or ry.get('publicKey')
            node["sid"] = ry.get('short-id') or ry.get('shortId') or ""
            
        return node
    except: return None

def find_dicts(obj):
    """é€’å½’éå† JSON æ ‘ï¼Œå¯»æ‰¾æ‰€æœ‰æ½œåœ¨å­—å…¸"""
    if isinstance(obj, dict):
        yield obj
        for v in obj.values(): yield from find_dicts(v)
    elif isinstance(obj, list):
        for i in obj: yield from find_dicts(i)

def main():
    if not os.path.exists(MANUAL_FILE): return
    with open(MANUAL_FILE, 'r', encoding='utf-8') as f:
        urls = list(set(re.findall(r'https?://[^\s\'"\[\],]+', f.read())))
    
    all_nodes = []
    print(f"ğŸ“‚ æ­£åœ¨ä¸¥æ ¼è§£æ {len(urls)} ä¸ªæº...")

    for url in urls:
        try:
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=12, context=ctx) as resp:
                text = resp.read().decode('utf-8', errors='ignore')
                # å…¼å®¹ JSON å’Œ YAML è§£æ
                try:
                    data = json.loads(text)
                except:
                    data = yaml.safe_load(text)
                
                if data:
                    for d in find_dicts(data):
                        node = parse_strict(d)
                        if node: all_nodes.append(node)
        except:
            print(f"âš ï¸ è®¿é—®å¤±è´¥: {url[:60]}...")

    # å»é‡
    uniq, seen = [], set()
    for n in all_nodes:
        k = (n['s'], n['p'], n['u'])
        if k not in seen: uniq.append(n); seen.add(k)

    clash_px = []
    bj_time = datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%d %H:%M")
    
    for i, n in enumerate(uniq):
        flag = get_geo(n['s'])
        name = f"{flag} {n['t'].upper()}_{n['s'].split('.')[-1]}_{i+1}"
        px = {"name": name, "type": n['t'], "server": n['s'], "port": n['p'], "skip-cert-verify": True}
        
        # åè®®å­—æ®µå¡«å……
        if n['t'] == 'hysteria2': px.update({"password": n['u'], "sni": n['sn']})
        elif n['t'] == 'juicity': px.update({"uuid": n['u'], "sni": n['sn'], "conntrack": True})
        elif n['t'] == 'naive': px.update({"username": n['u'], "password": n['pass'], "proxy-octet-stream": True})
        elif n['t'] == 'vless':
            px.update({"uuid": n['u'], "tls": True, "servername": n['sn']})
            if "pbk" in n: px.update({"network": "tcp", "reality-opts": {"public-key": n['pbk'], "short-id": n['sid']}})
        
        clash_px.append(px)
        if i % 10 == 0: time.sleep(0.5)

    conf = {
        "proxies": clash_px,
        "proxy-groups": [
            {"name": "ğŸš€ è‡ªåŠ¨é€‰æ‹©", "type": "url-test", "proxies": [p['name'] for p in clash_px], "url": "http://www.gstatic.com/generate_204", "interval": 300},
            {"name": "ğŸ”° æ‰‹åŠ¨åˆ‡æ¢", "type": "select", "proxies": ["ğŸš€ è‡ªåŠ¨é€‰æ‹©"] + [p['name'] for p in clash_px]},
            {"name": f"ğŸ•’ æ›´æ–°: {bj_time}", "type": "select", "proxies": ["ğŸš€ è‡ªåŠ¨é€‰æ‹©"]}
        ],
        "rules": ["MATCH,ğŸ”° æ‰‹åŠ¨åˆ‡æ¢"]
    }

    with open(f"{OUT_DIR}/clash.yaml", 'w', encoding='utf-8') as f:
        yaml.dump(conf, f, allow_unicode=True, sort_keys=False)
    
    print(f"âœ… è§£æå®Œæˆ! ä¸¥æ ¼åŒ¹é…èŠ‚ç‚¹æ•°: {len(clash_px)} | åŒ—äº¬æ—¶é—´: {bj_time}")

if __name__ == "__main__":
    main()
